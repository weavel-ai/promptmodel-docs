---
description: 'prompt connect - Promptmodel CLI Documentation'
---

# connect

```bash
prompt connect
```

> Connects your codebase to the dashboard.

All FunctionModel runs and ChatModel chat generations will now be sent to the connected ClI and requested from the connected environment.

These requests will use the API keys set in your local device, either defined in the `.env` file or set manually.

While connected, adding Promptmodel instances in your codebase will automatically add it to the dashboard.

```python {6-9} filename="your_fle.py"
from promptmodel import FunctionModel, DevClient

client = DevClient()

# Adding the block below will display FunctionModel "summarize" in the dashboard
@client.register
def summarize(text: str):
    outputs = FunctionModel("summarize").run(inputs={"text": text})
    return outputs.raw_output
```
